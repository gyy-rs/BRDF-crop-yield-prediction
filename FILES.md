# PROJECT STRUCTURE & FILES GUIDE

Complete guide to all files in the repository.

---

## ğŸ“‚ Directory Structure

```
crop-yield-prediction/
â”‚
â”œâ”€â”€ README.md                    # Main documentation
â”œâ”€â”€ QUICKSTART.md               # 5-minute quick start guide
â”œâ”€â”€ USAGE.md                    # Detailed usage guide
â”œâ”€â”€ LICENSE                     # MIT License
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚
â”œâ”€â”€ src/                        # Source code
â”‚   â”œâ”€â”€ model.py               # LSTM + Attention model
â”‚   â”œâ”€â”€ train.py               # Training & evaluation script
â”‚   â””â”€â”€ data_preprocessing.py  # Data preparation pipeline
â”‚
â”œâ”€â”€ data/                       # Data directory
â”‚   â”œâ”€â”€ raw/                    # Raw input data (you provide)
â”‚   â”‚   â”œâ”€â”€ raw_sif_data.csv
â”‚   â”‚   â”œâ”€â”€ raw_vis_data.csv
â”‚   â”‚   â””â”€â”€ raw_yield_data.csv
â”‚   â”œâ”€â”€ sample/                 # Sample data for testing
â”‚   â”‚   â””â”€â”€ sample_data.csv
â”‚   â”œâ”€â”€ final_yield_features.pkl       # Generated by preprocessing
â”‚   â”œâ”€â”€ final_yield_features.csv       # Generated by preprocessing
â”‚   â””â”€â”€ time_index_mapping.csv         # Generated by preprocessing
â”‚
â””â”€â”€ results/                    # Results directory
    â””â”€â”€ cv_results.csv         # Generated by training
```

---

## ğŸ“„ File Descriptions

### Documentation

| File | Purpose | Audience |
|------|---------|----------|
| **README.md** | Complete project documentation, architecture, references | Everyone |
| **QUICKSTART.md** | 5-minute setup and run guide | New users |
| **USAGE.md** | Detailed usage instructions and troubleshooting | Advanced users |
| **LICENSE** | MIT License terms | Legal |

### Source Code

#### `src/model.py`
- **Purpose**: Define LSTM+Attention neural network
- **Key Classes**:
  - `AttentionLSTMModel`: Main model class
- **Functions**:
  - `__init__()`: Initialize layers
  - `forward()`: Forward pass
- **Usage**: Imported by `train.py`

**Example Usage:**
```python
from model import AttentionLSTMModel

model = AttentionLSTMModel(
    input_dim=10,           # Features per timestep
    lstm_hidden_dim=64,     # Hidden units
    n_heads=4,              # Attention heads
    n_layers=2,             # LSTM layers
    dropout_rate=0.3
)
```

#### `src/train.py`
- **Purpose**: Train and evaluate model with cross-validation
- **Key Functions**:
  - `train_and_evaluate_fold()`: Train on single CV fold
  - `main()`: Orchestrate full training pipeline
- **Usage**: Run with `python train.py`

**What it does:**
1. Loads preprocessed features
2. Performs 10Ã—5-fold CV (50 iterations)
3. Reports Mean Â± Std metrics

**Output:**
- Console: Performance metrics
- CSV: `results/cv_results.csv`

#### `src/data_preprocessing.py`
- **Purpose**: Prepare raw data for model training
- **Key Functions**:
  - `brdf_degree()`: Apply BRDF correction
  - `compute_vegetation_indices()`: Calculate spectral indices
  - `compute_multi_angle_features()`: Multi-angle corrections
  - `aggregate_temporal_data()`: Time series aggregation
  - `main()`: Full preprocessing pipeline
- **Usage**: Run with `python data_preprocessing.py`

**What it does:**
1. Loads 3 CSV files (SIF, VIs, Yield)
2. Merges by sample_id and date
3. Filters to growing season (Mar-May)
4. Aggregates to 10-day periods
5. Pivots to feature matrix
6. Saves outputs

**Output:**
- `data/final_yield_features.pkl` - Binary format (recommended)
- `data/final_yield_features.csv` - Readable format
- `data/time_index_mapping.csv` - Temporal indices

### Configuration

#### `requirements.txt`
- **Purpose**: Python package dependencies
- **Usage**: `pip install -r requirements.txt`
- **Packages**:
  - torch: Deep learning framework
  - numpy, pandas: Data handling
  - scikit-learn: Preprocessing, metrics
  - tqdm: Progress bars

### Data Files

#### Input Data (`data/raw/`)

**raw_sif_data.csv**
```csv
sample_id,year,month,day,sif743,par,sza,vza,raa,iso_r,vol_r,geo_r,iso_n,vol_n,geo_n
1,2019,3,1,1.25,45.3,35.2,15.0,120.5,0.12,0.08,-0.05,0.18,0.15,-0.02
...
```

**raw_vis_data.csv**
```csv
sample_id,year,month,day,NDVI,NIRv,EVI2,GVMI,CSI,CIredEdge,EVI
1,2019,3,1,0.45,0.38,0.42,0.52,0.35,0.48,0.40
...
```

**raw_yield_data.csv**
```csv
sample_id,year,yield
1,2019,5200
...
```

#### Generated Data (`data/`)

**final_yield_features.pkl**
- Format: Python pickle
- Content: Processed DataFrame with:
  - Index: sample_id, year
  - Columns: Aggregated features (NDVI_0, NDVI_1, ..., yield)
  - Shape: (500 samples, 91 features)

**final_yield_features.csv**
- Format: CSV (for inspection)
- Same content as .pkl but readable

**time_index_mapping.csv**
```csv
time_index,start_date,end_date,numerical_index
03-1,2019-03-01,2019-03-10,0
03-2,2019-03-11,2019-03-20,1
...
```

### Results

#### `results/cv_results.csv`
- Generated by `train.py`
- Contains results from all 50 CV folds
```csv
r2,mse,mae
0.7842,12345.67,87.23
0.7956,11892.34,85.12
...
```

---

## ğŸ”„ Data Flow Diagram

```
RAW DATA
  â†“
  â”œâ”€ raw_sif_data.csv
  â”œâ”€ raw_vis_data.csv
  â””â”€ raw_yield_data.csv
  
        â†“ [data_preprocessing.py]
  
PROCESSED DATA
  â”œâ”€ final_yield_features.pkl     â† model.py reads this
  â”œâ”€ final_yield_features.csv
  â””â”€ time_index_mapping.csv
  
        â†“ [train.py]
  
TRAINED MODEL & RESULTS
  â”œâ”€ cv_results.csv
  â””â”€ Console output
```

---

## ğŸ“Š Typical Workflow

### Day 1: Setup
```bash
git clone ...
cd crop-yield-prediction
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Day 2: Data Preparation
```bash
# Copy your data files
cp my_sif.csv data/raw/raw_sif_data.csv
cp my_vis.csv data/raw/raw_vis_data.csv
cp my_yield.csv data/raw/raw_yield_data.csv

# Run preprocessing
cd src
python data_preprocessing.py
```

### Day 3: Training
```bash
# Train model
python train.py

# View results
cat ../results/cv_results.csv
```

---

## ğŸ”‘ Key Files to Modify

### For Quick Testing
- Use `data/sample/sample_data.csv` (no modifications needed)

### For Your Data
1. **Prepare data** â†’ Place CSVs in `data/raw/`
2. **Customize preprocessing** â†’ Edit `src/data_preprocessing.py`
3. **Adjust model** â†’ Edit hyperparameters in `src/train.py`

### For Deployment
- Save trained model weights
- Create prediction script
- Integrate with downstream systems

---

## ğŸ“ File Sizes (Typical)

| File | Size | Notes |
|------|------|-------|
| raw_sif_data.csv | 50-100 MB | ~10,000 observations |
| raw_vis_data.csv | 30-50 MB | Same observations |
| raw_yield_data.csv | <1 MB | ~500 fields |
| final_yield_features.pkl | 5-10 MB | Processed, 500 samples |
| cv_results.csv | <100 KB | 50 folds Ã— 3 metrics |

---

## ğŸ”— File Dependencies

```
model.py
  â†‘
  â””â”€ (imported by) train.py
                     â†“
                     (reads) final_yield_features.pkl
                     â†‘
                     (generated by) data_preprocessing.py
                     â†‘
                     (reads) raw_sif_data.csv
                            raw_vis_data.csv
                            raw_yield_data.csv
```

---

## âœ… Checklist Before Running

- [ ] Virtual environment activated
- [ ] Dependencies installed (`pip install -r requirements.txt`)
- [ ] Raw data CSV files in `data/raw/` (or using sample data)
- [ ] Output directories exist (`data/`, `results/`)
- [ ] At least 2GB free disk space

---

## ğŸ“– Reading Guide

**For Quick Start:**
1. README.md (overview)
2. QUICKSTART.md (5 minutes)
3. Run with sample data

**For Full Understanding:**
1. README.md (complete architecture)
2. USAGE.md (detailed guide)
3. Read source code (src/*.py)
4. Review sample output

**For Custom Implementation:**
1. USAGE.md (Advanced Usage section)
2. Edit relevant source files
3. Test with sample data first
4. Deploy with your data

---

## ğŸ› Debugging

To understand what each script does, add print statements:

```python
# In data_preprocessing.py
print(f"Loaded {len(df)} rows")
print(f"Columns: {df.columns.tolist()}")

# In train.py  
print(f"Device: {device}")
print(f"Model: {model}")
```

Or run Python interactively:

```bash
cd src
python -i train.py  # Drop to shell after running
```

---

**Last Updated**: February 2024
